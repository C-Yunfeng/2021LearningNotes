一、 自我介绍

面试官您好，我是崔一帆，目前是对外经济贸易大学的一名大四生，专业是信息管理与信息系统

我在校期间学习过MySQL，Oracle，MongoDB等多种数据库，熟悉SQL的使用。

同时我做过一些机器学习的项目，比如设计智能货柜系统，投资者情绪对股票收益率的影响，

也跟老师一起做过科研项目，如使用AutoEncoder模型和K-means算法选出合适的股票投资组合。

因为自信满足数据分析岗位的要求，所以参加了这个岗位的面试，期待能在贵公司发挥自己的专业和特长。



#### 二、项目经历

##### 1. 智能货柜

> imageAI的预训练模型resnet，这个是可以动态识别的。但缺点是对光线要求高，而且对商品的姿势也有要求。之后在另一个课程中我又重新改进了，用了CNN和Dectron来识别静态的图片，最后识别效果也很好，测试集的AUC都在90以上。
>
> 一秒会有10张，做10次预测，投票看结果

- [x] CV2：cv2.VideoCapture(0)

- [x] ImageAI

  ```python
  from imageai.Detection import ObjectDetection
  detector.setModelTypeAsRetinaNet()
  detector.setModelPath( os.path.join(execution_path , "resnet50_coco_best_v2.0.1.h5"))
  detector.loadModel()
  ```

##### 2.  蜡烛图AutoEncoder

> tushare，蜡烛图（窗口大小）
>
> 【在此之前我们也用CNN做了一个预实验，将蜡烛图直接作为模型的输入，添加了Dropout层，全链接层之后用于分类，经过交叉验证之后模型的准确率为58%】，
>
> 但是这个只能用于判断股票涨跌，不能给决策提供更多的信息，所以我们后来又做了更复杂的事情。
>
> 首先用一些效果比较好的AutoEncoder模型将蜡烛图压缩成低维的向量，比如100维，然后用k-means对所有股票进行聚类，这样就得到了多个走势相似的股票组合，最后再使用夏普指数进行排序，选出高收益低风险的股票。
>
> 聚类的K值选取，根据实际的走势判断大概有十几种，所以K定在7~30之间，但聚类的评价指标只是一个中间指标？？？？

- [x] Tushare：一个python财经数据接口包，主要实现对股票等金融数据从数据采集、清洗加工 到 数据存储的过程


- [x] AutoEncoder

  是一个漏斗状的神经网络模型，可以将高纬度的图片压缩成低纬度的向量（压缩效果评价标准为是否能复原）（使用到了卷积和上采样）（卷积核，点乘）

- [x] K-means原理

  损失函数为：方差

  最小化类内方差
  
- [x] 夏普：预期收益率-实际利率/方差

##### 3. 投资者情绪股票收益率

- [x] MongoDB

  NoSQL = Not Only SQL

  数据结构是键值对，类似json的存储格式

  由于是去年疫情期间做的，当时股市受疫情影响很大，所以数据选取了疫情之前的即19年到20年3月的数据

- [x] SnowNLP的贝叶斯

  14年，有点早，所以是用的简单的朴素贝叶斯模型

  有预训练，但是在商品评论的数据集上寻来你的，而且当时还没有了解BERT以及非监督算法，所以另外标注了2000条评论用来fine-tune（10秒一个，因为有很多术语）

- [x] 投资者情绪

  很早很简单的04年的，参考央视看盘BSI指数（Bullish Sentiment Index），即看涨的帖子数占所有帖子数的比例

- [ ] ARMA模型

  Adaptive Regression Moving Average，自回归滑动平均，

- [x] 收益率的计算

  有多种计算方式，如收益/本金，但由于没有实际进行投资，且用的是历史交易数据，所以采用的计算方法是：(收盘价格-[开盘价格](https://baike.baidu.com/item/开盘价格))/开盘价格

  - 缺点：股票市场很复杂，受外部环境的影响很大，最终实际收益率和预计收益率变动方向相同的，即ACC只有61%


##### 4. 广告文章识别

> 因为我关注了一些技术类公众号，每天可以学新内容，但是有的公众号会经常发一些广告文章，比如Python训练营，机器学习训练营之类的，很影响阅读体验。所以就想做一个能够自动识别广告文章的算法。
>
> 首先是从微信APP里爬文章，爬了有2万篇文章，由于文章被删除等原因，广告文章很少，正负样本不平衡，所以划分好训练集测试集之后，对训练集的文本进行增强，这里用的是回译，就是把语言A翻译成语言B再翻译回语言A，这样可以在保证语义不变的情况下增加文本的表述方式。
>
> 经过清洗之后使用BERT模型把词语转化为向量，在模型最后添加一个softmax层用于分类，最终AUC值为84%
>
> 对比试验全文和关键词

- [x] [TF-IDF原理](https://mp.weixin.qq.com/s/GXpT8Db2cSlRDUj8Ynza3A)

- [ ] TEXTRANK原理

- [x] 回译

- [x] BERT模型：谷歌团队2018年发布的预训练模型，在大量数据上进行训练（没有人工标注，随机mask的方法来

- [x] softmax层原理：在数学公式上其实是等价的，比如sigmoid：$s(x)=\frac{1}{1+e^{-x}}$，softmax是：$\frac{1}{1+e^{x_j-x_i}}$



##### 5. 众安黑客松

> 这是去年9月在一家保险公司参加的保险风控比赛，小组三人在2天内
>
> 在写代码之前首先了解了一些保险行业的知识，因为技术是为了驱动业务的，所以对实际业务知识的了解是必要的。然后是对数据集进行处理，如缺失值处理、对少数类样本进行采样等。同时我们也多了一些数据探索性分析，比如分析特征的分布等等。
>
> 之后就是特征工程，比如对日期特征做差，将涉及金额类的特征相乘以计算总金额。最后我们使用五折交叉验证并融合了Xgboost和LightGBM两个模型，最终是达到了线下88线上82的分数。

- [ ] 查看一些特征的分别对应0/1(正常/风险)的分布

- [ ] 数据清洗

  - [ ] 缺失值处理
    - [ ] 类别型变-1
  - [ ] 标准化

- [ ] 采样

  - [ ] 1:5左右，

  - [ ] SMOTE算法

    对少样本a，随机抽一个最近的样本b，然后从a与b的连线上随机取一个点c作为新的少数类样本

- [ ] 特征工程

  - [ ] 时间特征处理

    - [ ] 时间发生日-报告日【正常案件和异常案件的时间间隔不同】

  - [ ] 构造新特征

    - [ ] 构造比例

      - [ ] 历史支付金额/历史索赔金额
        - [ ] 比如骗保案件，历史支付金额可能为0
      - [ ] 历史最大住院日数/历史住院日数

    - [ ] 作差

      我们发现如history_inpatient_number及history_disease_inpatient_number两个特征的分布趋势相似但数值相差较大。从保险业务分析，如果申保人想要骗保，则需要伪造生病的证据，而实际上并没有疾病。因此用history_disease_inpatient_number减history_inpatient_number就可以得出非疾病原因住院的次数，差值越大说明此申保人的风险越大。其他类似特征也同样作差。

    - [ ] 相乘

      如下图左侧两张特征分布图可以看出，对于申请次数、驳回次数、申请金额以及实赔金额来说，属于风险案件的特征呈尖峰分布，而属于正常案件的特征呈平稳分布。这也符合保险业务的实际情况。

      因此我们将“历史申请次数”乘以“历史申请金额”作为“历史总金额”，将“历史驳回次数”乘以“历史实赔金额”作为另一个特征(姑且叫它“历史实赔总金额”，虽然它没有对应的实际意义，但数值越大代表风险越高，因此可以保留)，以此构建出区分度更大的特征，便于分类器分类。

- [ ] 模型

  - [ ] 模型介绍

    ![image-20210315013623318](C:\Users\18810\AppData\Roaming\Typora\typora-user-images\image-20210315013623318.png)

    - [ ] 支持线性分类器![image-20210315013809307](C:\Users\18810\AppData\Roaming\Typora\typora-user-images\image-20210315013809307.png)
    - [ ] 

  - [ ] 模型融合

    |         | 五折交叉验证microScore | 比例 |      |
    | ------- | ---------------------- | ---- | ---- |
    | lgbm    | 0.8857                 | 70   |      |
    | XGBoost | 0.8805                 | 30   |      |




##### 6. 国赛

> 





##### 7. 其他

- [ ] 身边不可超越的人

  > 室友唐百川，室友孙逸文。
  >
  > 怎么克服的？唐百川技术层面：前期是他带着我学的，后来入门之后我就会自己找一些学习资料，当然肯定不会私藏啊，我们的微信聊天里面都是发的技术文章。超越算不上，但如果在具体某个事件里超越，那是有可能的，比如一些课的成绩，但总之还是不容易赶上的。
